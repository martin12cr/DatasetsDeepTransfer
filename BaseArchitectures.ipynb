{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a27e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from tcn import TCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cd9347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN \n",
    "####################\n",
    "\n",
    "def build_CNN(hp):\n",
    "    \n",
    "\n",
    "    num_layers = hp.Int('num_layers', min_value=1, max_value=2, step=1)\n",
    "    filters_0 = hp.Int('filters_0', min_value=12, max_value=132, step=24)\n",
    "    kernel_0 = hp.Int('kernel_0', min_value=2, max_value=12, step=2)\n",
    "    activation = hp.Choice(\"activation\", ['linear',\"relu\", \"tanh\"])   #### QUITAR Y PONER CON RELU\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    pool_sizes= hp.Choice('pool', values=[0, 2])\n",
    "    \n",
    "    \n",
    "    # define model\n",
    "    inputs = tensorflow.keras.layers.Input(shape=x1[0,1:,:].shape)\n",
    "   \n",
    "    \n",
    "    # First conv block\n",
    "    x = tensorflow.keras.layers.Conv1D(filters_0, kernel_0, activation=activation, padding=\"same\")(inputs)\n",
    "    x=BatchNormalization()(x)\n",
    "    \n",
    "    if pool_sizes and x.shape[-2] // pool_sizes > 1:\n",
    "        x = tensorflow.keras.layers.MaxPool1D(pool_size=pool_sizes)(x)\n",
    "    \n",
    "   # rest conv block\n",
    "    if num_layers>1:\n",
    "        for i in range(num_layers-1):\n",
    "            x=tensorflow.keras.layers.Conv1D(filters=hp.Int(f\"filters_{i+1}\", min_value=12, max_value=132, step=24), kernel_size=hp.Int(f\"kernel_{i+1}\", min_value=2, max_value=12, step=2),\n",
    "                activation=activation, padding=\"same\")(x)\n",
    "        \n",
    "            if pool_sizes and x.shape[-2] // pool_sizes > 1:\n",
    "                x = tensorflow.keras.layers.MaxPool1D(pool_size=pool_sizes)(x)\n",
    "    \n",
    "    x = tensorflow.keras.layers.Flatten()(x)\n",
    "    x = tensorflow.keras.layers.Dense(y1.shape[1])(x)\n",
    "\n",
    "    model = tensorflow.keras.Model(inputs=inputs, outputs=x)\n",
    "    opt = tensorflow.keras.optimizers.Adam(learning_rate=hp_learning_rate)\n",
    "    model.compile(opt, 'mean_absolute_percentage_error')\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# TCN \n",
    "####################\n",
    "\n",
    "def build_TCN(hp):\n",
    "    \n",
    "    # Choose an optimal value for several parameters\n",
    "    nb_filters = hp.Int('filters', min_value=12, max_value=132, step=24)\n",
    "    kernel_size = hp.Int('kernel', min_value=2, max_value=12, step=2)\n",
    "    activation = hp.Choice(\"activation\", ['linear',\"relu\", \"tanh\"])   ###### RELU\n",
    "    return_sequences = hp.Choice(\"sequences\", [True, False])\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    \n",
    "    # Choose optimal value for dilations\n",
    "    dilatCod = hp.Int('dilatCod', min_value=0, max_value=1, step=1)  \n",
    "    listDilations=[[1, 2, 4, 8], [1, 2, 4, 8, 16]]\n",
    "    dilations=listDilations[dilatCod]\n",
    "    #dilations= [1, 2, 4, 8]\n",
    "    \n",
    "    # model input\n",
    "    inputs = tf.keras.layers.Input(shape=x1[0,1:,:].shape)\n",
    "    \n",
    "    # model characteristics \n",
    "    x = TCN(\n",
    "        nb_filters=nb_filters,  #\n",
    "        kernel_size=kernel_size,# \n",
    "        nb_stacks=1,\n",
    "        dilations=dilations,    #\n",
    "        use_skip_connections=True,\n",
    "        dropout_rate=0.0,\n",
    "        return_sequences=return_sequences,    #\n",
    "        activation=activation, #\n",
    "        use_batch_norm=False,\n",
    "        padding='causal',\n",
    "    )(inputs)\n",
    "    \n",
    "    \n",
    "    if return_sequences:\n",
    "        x = tensorflow.keras.layers.Flatten()(x)     \n",
    "    x = tensorflow.keras.layers.Dense(y1.shape[1])(x)\n",
    "    model = tensorflow.keras.Model(inputs=inputs, outputs=x)\n",
    "    \n",
    "    # compile model\n",
    "    opt = tensorflow.keras.optimizers.Adam(learning_rate=hp_learning_rate)\n",
    "    model.compile(opt, 'mean_absolute_percentage_error')\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# LSTM \n",
    "####################\n",
    "\n",
    "def build_LSTM(hp):\n",
    "    \n",
    "    # Choose an optimal value for several parameters\n",
    "\n",
    "    recurrent_units= hp.Int('units', min_value=12, max_value=132, step=24)\n",
    "    activation = hp.Choice(\"activation\", ['linear',\"relu\", \"tanh\"])  #########  RELU\n",
    "    recurrent_dropout=0.0\n",
    "    return_sequences=hp.Choice(\"return_sequences\", [True, False])\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    \n",
    "    inputs = tensorflow.keras.layers.Input(shape=x1[0,1:,:].shape)\n",
    "    \n",
    "    # LSTM layers\n",
    "    x = tensorflow.keras.layers.LSTM(recurrent_units, activation= activation, return_sequences=return_sequences)(inputs)\n",
    "    \n",
    "    if return_sequences:\n",
    "        x = tensorflow.keras.layers.Flatten()(x)\n",
    "    \n",
    "    x = tensorflow.keras.layers.Dense(y1.shape[1])(x)\n",
    "   \n",
    "    model = tensorflow.keras.Model(inputs=inputs, outputs=x)\n",
    "    \n",
    "    \n",
    "    # compile model\n",
    "    opt = tensorflow.keras.optimizers.Adam(learning_rate=hp_learning_rate)\n",
    "    model.compile(opt, 'mean_absolute_percentage_error')\n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
